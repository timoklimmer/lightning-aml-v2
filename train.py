import argparse
import json
import os
import sys

import mlflow
import pytorch_lightning as pl
import torch
import nebulaml as nm
from pytorch_lightning import loggers as pl_loggers
from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.strategies import DeepSpeedStrategy, StrategyRegistry

from utils.codetimer import CodeTimer
from utils.dynamic_class_loading import (
    ensure_data_module_class_exists,
    ensure_model_class_exists,
    get_data_module_class,
    get_model_class,
)

# argument parsing
parser = argparse.ArgumentParser()
# -- model
parser.add_argument(
    "--model",
    type=str,
    required=True,
    help="Class name of the model to train. Make sure there is a corresponding script and class in folder 'models'.",
)
# -- data module
parser.add_argument(
    "--data-module",
    type=str,
    required=True,
    help="Class name of the data module. Make sure there is a corresponding script and class in folder 'data'.",
)
# -- training_strategy
# see https://pytorch-lightning.readthedocs.io/en/stable/extensions/strategy.html#id1 for available strategies and/or
# run:
# from pytorch_lightning.strategies import StrategyRegistry
# StrategyRegistry.available_strategies()
parser.add_argument(
    "--training-strategy",
    type=str,
    required=True,
    choices=StrategyRegistry.available_strategies(),
    help="Training strategy for Lightning.",
)
# -- max-epochs
parser.add_argument(
    "--max-epochs", type=int, default=10, help="Maximum number of epochs to train."
)
# -- progress-bar-refresh-rate
parser.add_argument(
    "--progress-bar-refresh-rate",
    default=100,
    type=int,
    help="Refresh rate for training progress bar",
)
parser.add_argument("--data_folder", type=str, help="Path to the dataset")
parser.add_argument("--batch_size", type=int, default=32, help="Batch size")
parser.add_argument("--enable_nebula", default="False", help="Enable Nebula")
args = parser.parse_args()
enable_nebula = args.enable_nebula.lower() in ("yes", "true", "t", "y", "1")

# collect some infos about the environment we are running in
# number of nodes
number_nodes = int(os.environ.get("AZUREML_NODE_COUNT", 1))
# number of GPUs/"devices" per node
number_devices_per_node = int(
    os.environ.get("AZ_BATCHAI_GPU_COUNT", torch.cuda.device_count())
)
# are we running in a Compute Cluster?
is_compute_cluster = "AZUREML_RUN_ID" in os.environ
# are we running on the head node?
is_head_node = int(os.environ.get("RANK", 0)) == 0
# IP address
ip_address = os.environ.get("AZ_BATCHAI_NODE_IP", "(not available)")


# say hello and print some context
header_text = f"Let's train model '{args.model}' üôÇ"
print(100 * "*")
print(header_text)
print(100 * "*")
print("SCRIPT ARGUMENTS")
print("----------------")
print(f"Model                      : {args.model}")
print(f"Training Strategy          : {args.training_strategy}")
print(f"Maximum Epochs             : {args.max_epochs}")
print(f"Progress Bar Refresh Rate  : {args.progress_bar_refresh_rate}")
print("")
print("ENVIRONMENT")
print("-----------")
print(f"Number Of Nodes            : {number_nodes}")
print(f"Number Of Devices per Node : {number_devices_per_node}")
print(f"Is AzureML Compute Cluster : {is_compute_cluster}")
print(f"Is First Node              : {is_head_node}")
print(f"IP Address                 : {ip_address}")
print("")
print("ENVIRONMENT VARIABLES")
print("---------------------")
for env_var in sorted(os.environ):
    print(f"{env_var}: {os.environ[env_var]}")
print("")
print(100 * "-")
sys.stdout.flush()

# use a local tracking URI for mlflow if we are not running in a Compute Cluster
if not is_compute_cluster:
    mlflow.set_tracking_uri("./@logs/mlruns")

# ensure that the class declarations for the data module and for the model actually exist
ensure_data_module_class_exists(args.data_module)
ensure_model_class_exists(args.model)

# use custom DeepSpeed configuration when available
effective_strategy = args.training_strategy


# Define helper function to update the trainer configuration with Nebula settings
def configure_nebula(trainer_config, deepspeed_config=None):
    if deepspeed_config:
        deepspeed_config["nebula"] = {
            "enabled": True,
            "persistent_storage_path": os.path.abspath(
                deepspeed_config.get("nebula", {}).get(
                    "persistent_storage_path", "./outputs"
                )
            ),
        }
        print(json.dumps(deepspeed_config, indent=4))
        trainer_config["strategy"] = nm.NebulaDeepspeedStrategy(config=deepspeed_config)
    else:
        print("using Nebula")
        print("--------------")
        config_params = {
            "persistent_storage_path": os.path.abspath("./outputs"),
            "persistent_time_interval": 100,
        }
        trainer_config["callbacks"].append(
            nm.NebulaCallback(config_params=config_params)
        )
        trainer_config["plugins"] = [nm.NebulaCheckpointIO()]


trainer_config = {
    "accelerator": "gpu",
    "num_nodes": number_nodes,
    "devices": number_devices_per_node,
    "max_epochs": args.max_epochs,
    "logger": pl_loggers.TensorBoardLogger(
        save_dir=("outputs" if is_compute_cluster else "@logs")
    ),
    "callbacks": [
        TQDMProgressBar(refresh_rate=args.progress_bar_refresh_rate),
        EarlyStopping(monitor="val_loss", mode="min", patience=30),
    ],
}

# Default DeepSpeed configuration
if args.training_strategy == "deepspeed" and os.path.exists("ds_config.json"):
    with open("ds_config.json") as deepspeed_config_file:
        deepspeed_config = json.load(deepspeed_config_file)
    trainer_config["strategy"] = DeepSpeedStrategy(config=deepspeed_config)
    trainer_config["callbacks"].append(
        ModelCheckpoint(filename="{epoch}", every_n_epochs=10)
    )
else:
    deepspeed_config = None

# Apply Nebula configurations if the flag is set
if enable_nebula:
    configure_nebula(trainer_config, deepspeed_config)

with CodeTimer("Set up trainer"):
    trainer = pl.Trainer(**trainer_config)

# setup data module
with CodeTimer("Set up data module"):
    data_module_class = get_data_module_class(args.data_module)
    if hasattr(args, "data_folder") and args.data_folder:
        data_module = data_module_class(
            data_folder=args.data_folder, batch_size=args.batch_size
        )
    # using built-in datasets
    elif args.data_module == "MNIST":
        data_module = data_module_class()
    else:
        raise ValueError("Please provide the data folder argument.")

# setup model
with CodeTimer("Set up model"):
    model_class = get_model_class(args.model)
    # Check if there are additional arguments to pass to the model class
    model_args = vars(args) if hasattr(args, "model_args") and args.model_args else {}
    # Instantiate the model with or without arguments based on the condition
    model = model_class(**model_args) if model_args else model_class()

# train model
with mlflow.start_run() as run:
    if is_head_node:
        mlflow.autolog()
        sys.stdout.flush()
    with CodeTimer("Train model") as code_timer:
        trainer.fit(model, data_module)
        net_training_time_wall = code_timer.exit_with_infos()["time_delta_str"]
    if is_head_node:
        mlflow.log_param("net_training_time_wall", net_training_time_wall)

# test model
with CodeTimer("Test model"):
    trainer.test(model, data_module)

# done
print("‚úîÔ∏è  Done.")
print("")
